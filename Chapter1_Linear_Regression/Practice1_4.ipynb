{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation Practice.1-4\n",
    "## Forward and Backward Propagation with $y = \\theta_{1} x + \\theta_{0}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Dataset Generation\n",
    "NumPy를 이용하여 다음과 같은 x_data, y_data를 만드시오.\n",
    "\n",
    "| Data Index | Study Hour | Math Score |\n",
    "|:-:|:-:|:-:|\n",
    "|0|1|2|\n",
    "|1|2|3|\n",
    "|2|3|4|\n",
    "|3|4|5|\n",
    "|4|5|6|\n",
    "\n",
    "위의 data는 $y = \\theta_{1} x + \\theta_{0}$로 modeling을 할 수 있다.\n",
    "이 model에 대한 forward propagation은 다음과 같다.\n",
    "\n",
    "<img src=\"./images/1_4_image1.png\" width = 1000>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서 우리가 학습할 값들은 $\\theta_{1}, \\theta_{0}$이고 따라서 backward propagation의 대상은 2개이고, Practice1-3까지 $\\theta = \\theta - \\alpha * \\frac{\\partial J}{\\partial \\theta}$가 이제 $\\theta_{1} = \\theta_{1} - \\alpha * \\frac{\\partial J(\\theta_{1}, \\theta_{0})}{\\partial \\theta_{1}}, \\theta_{0} = \\theta_{0} - \\alpha * \\frac{\\partial J(\\theta_{1}, \\theta_{0})}{\\partial \\theta_{0}}$로 2개가 된다.\n",
    "\n",
    "이제 이 dataset을 numpy를 이용하여 만들어보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "##### Your Code #####\n",
    "x_data = \n",
    "y_data = \n",
    "##### Your Code #####\n",
    "\n",
    "print(x_data, y_data)\n",
    "fig, ax = plt.subplots(figsize = (5,5))\n",
    "ax.plot(x_data, y_data, 'bo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "[0 1 2 3 4] [1 2 3 4 5]\n",
    "<img src=\"./images/1_4_image2.png\" width = 300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### Node Implementation\n",
    "Bias가 추가된 model에서는 Practice1-3까지 사용했던 node들로 충분하다.\n",
    "따라서 전에 만들었던 node들을 불러오자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Load The Previous Nodes\n",
    "    1. plus_node()\n",
    "    2. minus_node()\n",
    "    3. mul_node()\n",
    "    4. square_node()\n",
    "    5. cost_node()\n",
    "'''\n",
    "##### Your Code(Load Nodes) #####\n",
    "\n",
    "\n",
    "\n",
    "##### Your Code(Load Nodes) #####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 model에 대하여 Batch Gradient Descent Method를 적용한 사진은 다음과 같다.\n",
    "\n",
    "<img src=\"./images/1_4_image4.png\" width = 1000>\n",
    "\n",
    "Numpy를 이용하여 위 model의 forward propagation, backward propagation을 구현하고\n",
    "실제 학습을 진행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1, theta0 = 0, 0\n",
    "lr = 0.01\n",
    "epochs = 1000\n",
    "\n",
    "##### Your Code(Model Implmenataion) #####\n",
    "\n",
    "##### Your Code(Model Implmenataion) #####\n",
    "\n",
    "loss_list = []\n",
    "theta1_list, theta0_list = [], []\n",
    "\n",
    "for i in range(epochs):\n",
    "    ##### Your Code(Forward Propagation) #####\n",
    "    \n",
    "    ##### Your Code(Forward Propagation) #####\n",
    "\n",
    "\n",
    "    \n",
    "    ##### Your Code(Backward Propagation) #####\n",
    "    \n",
    "    ##### Your Code(Backward Propagation) #####\n",
    "    \n",
    "    \n",
    "    ##### Parameter Update #####\n",
    "    # Update, Visualization을 사용하기 위해선\n",
    "    # theta1, theta0의 gradient들을 dTheta1, dTheta0로 설정해주세요\n",
    "    \n",
    "    theta1 = theta1 - lr*np.sum(dTheta1)\n",
    "    theta0 = theta0 - lr*np.sum(dTheta0)\n",
    "    \n",
    "    loss_list.append(C)\n",
    "    theta1_list.append(theta1)\n",
    "    theta0_list.append(theta0)\n",
    "    if i % 100 == 0:\n",
    "        print('Cost: {0:7.3f}\\t theta1:{1:7.3f}\\t theta0:{2:7.3f}'.format(C, theta1, theta0))\n",
    "    ##### Parameter Update #####\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:** <br>\n",
    "Cost:  11.000\t theta1:  0.160\t theta0:  0.060 <br>\n",
    "Cost:   0.034\t theta1:  1.111\t theta0:  0.684  <br>\n",
    "Cost:   0.010\t theta1:  1.061\t theta0:  0.826 <br>\n",
    "Cost:   0.003\t theta1:  1.033\t theta0:  0.905 <br>\n",
    "Cost:   0.001\t theta1:  1.018\t theta0:  0.948 <br>\n",
    "Cost:   0.000\t theta1:  1.010\t theta0:  0.971 <br>\n",
    "Cost:   0.000\t theta1:  1.006\t theta0:  0.984 <br>\n",
    "Cost:   0.000\t theta1:  1.003\t theta0:  0.991 <br>\n",
    "Cost:   0.000\t theta1:  1.002\t theta0:  0.995 <br>\n",
    "Cost:   0.000\t theta1:  1.001\t theta0:  0.997 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (20,10))\n",
    "ax1.grid()\n",
    "ax1.plot(loss_list)\n",
    "ax1.set_title(\"loss\", fontsize = 50)\n",
    "\n",
    "#fig, ax1 = plt.subplots(figsize = (10,10))\n",
    "ax2.plot(theta1_list, label = r\"$\\theta_{1}$\")\n",
    "ax2.plot(theta0_list, label = r\"$\\theta_{0}$\")\n",
    "fig.legend(fontsize = 'xx-large')\n",
    "ax2.set_title(r\"$\\theta_{1}, \\theta_{0} Update$\", fontsize = 50)\n",
    "ax2.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected Output:**\n",
    "\n",
    "<img src=\"./images/1_4_image3.png\" width = 1000>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
